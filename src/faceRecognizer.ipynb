{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQWuwQvHF0BY"
   },
   "source": [
    "## FaceRecognizer\n",
    "#### The Following Code was trained on Google Colab because of GPU restrictions\n",
    "#### Input: \n",
    "- Training data from drive (or local disk if training from local disk in the future)\n",
    "- Testing data from drive (or local disk if training from local disk in the future)\n",
    "\n",
    "#### Output:\n",
    "- Predicted Label corresonding to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfRG-vK0HCFT"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import os\n",
    "from os.path import isdir\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEjDREAqGDws"
   },
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    #if image is not having face\n",
    "    if len(results)==0:\n",
    "        return []\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Naho_aJwGfBw"
   },
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "    # if image is not having any face\n",
    "    if len(face) == 0:\n",
    "        continue\n",
    "        # store\n",
    "        faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9k0jo3U_GiNY"
   },
   "outputs": [],
   "source": [
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iizUGByJGBu"
   },
   "source": [
    "#### Loading Dataset from FaceDetectorTrain and FaceDetectorTest from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pw95Hi9YGnQy",
    "outputId": "5cdfe654-50d6-4c2e-f6a5-0419795b81d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 160, 160, 3)\n",
      "(118, 160, 160, 3)\n",
      "(561,)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset(\"../data/FaceDetectorTrain/\")\n",
    "testX, testy = load_dataset(\"../data/FaceDetectorTest/\")\n",
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfMBKeAiJhry"
   },
   "source": [
    "#### keraspath variable is used to load the model, as we are using facenet model (pretrained model ) \n",
    "- facenet_keras.h5 pretrained model that was used was downloaded from manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzklGrfXJgWT"
   },
   "outputs": [],
   "source": [
    "keraspath=\"../model/facenet_keras.h5\"\n",
    "from keras.models import load_model\n",
    "model = load_model(keraspath,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUpNMN4vGqXt"
   },
   "outputs": [],
   "source": [
    "# used to convert iamge of shape(160*160*3) into vectors(1 * 128)\n",
    "def get_embedding(model, face_pixels):\n",
    "  # converting to float data type\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "  # finding mean,std of face\n",
    "    (mean, std) = (face_pixels.mean(), face_pixels.std())\n",
    "  # Normalizing the vector\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VqZ696SVKfuE",
    "outputId": "ef23cd95-d25a-43f6-85ea-a01f0d86140b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 128)\n"
     ]
    }
   ],
   "source": [
    "#convert each image present in trainX to embedded vector \n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pu_uqUEGKorQ",
    "outputId": "f2ee387e-d532-4d31-cd47-df54f07ea9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 128)\n"
     ]
    }
   ],
   "source": [
    "#convert each image present in testX to embedded vector\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqwrvZ5lPSYJ"
   },
   "source": [
    "#### We used Random forest classifier to train our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qWDkxa5AK3WK",
    "outputId": "41aaf100-7541-44b6-a49f-78cdc0af51cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9915254237288136\n"
     ]
    }
   ],
   "source": [
    "trainX=newTrainX\n",
    "trainy=trainy\n",
    "testX=newTestX\n",
    "testy=testy\n",
    "concat = np.concatenate((trainX,testX),axis=0)\n",
    "\n",
    "lent = len(trainX)\n",
    "\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "concat = in_encoder.transform(concat)\n",
    "\n",
    "trainX = concat[:lent]\n",
    "testX = concat[lent:]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500,n_jobs=-1)\n",
    "clf.fit(trainX,trainy)\n",
    "predicted = clf.predict(testX)\n",
    "print(accuracy_score(testy,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We saved pickle files corresponds to the following on our local machines, to save time during further computations:\n",
    "- training data\n",
    "- training label\n",
    "- testing data\n",
    "- testing label\n",
    "- classifier (it is an object of type random forest)\n",
    "- model ( which is pretrained )\n",
    "\n",
    "#### The directory structures in the above code have been changed to use relative paths with respect to the final codes directory structure for future scenarios of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "faceRecognizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
